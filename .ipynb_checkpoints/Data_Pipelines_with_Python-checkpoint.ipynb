{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Uwjnhit2BIJz"
   },
   "outputs": [],
   "source": [
    "# Data Pipelines\n",
    "# Extract Data, Transform, Load and Analyze.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PHA23c1DCGZ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JUnqwKxKFCF9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'airflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kc/z0kxmt_x1nxd1n5bmvjl97g00000gn/T/ipykernel_2428/2963362405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_operator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPythonOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCSToGCSOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'airflow'"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.providers.google.cloud.operators.gcs import GCSToGCSOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'Safaricom',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 4, 10),\n",
    "    'email': ['newton.kipngeno@student.moringaschool.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 3,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'billing_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Pipeline for billing',\n",
    "    schedule_interval=timedelta(days=1),\n",
    ")\n",
    "\n",
    "# Functions\n",
    "# Extract data\n",
    "def extract_csv(filename):\n",
    "  data = pd.read_csv(filename)\n",
    "  return data\n",
    "\n",
    "# transform\n",
    "def transform_data(dataframe):\n",
    "  # Remove duplicates\n",
    "  dataframe = dataframe.drop_duplicates()\n",
    "  # remove nulls\n",
    "  dataframe = dataframe.dropna()\n",
    "  return dataframe\n",
    "\n",
    "#load data\n",
    "def load_data(df):\n",
    "    filename = datetime.today().strftime(\"%Y%m%d\") + '_billing.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    return filename\n",
    "\n",
    "def upload_to_gcs(filename):\n",
    "    gcs_hook = GoogleCloudStorageHook()\n",
    "    gcs_hook.upload(\n",
    "        bucket='mybucket',\n",
    "        object='data/cdrs/' + filename,\n",
    "        filename=filename,\n",
    "    )\n",
    "    \n",
    "extract = PythonOperator(\n",
    "    task_id='extract_csv',\n",
    "    python_callable=extract_csv,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "transform = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "load = PythonOperator(\n",
    "    task_id='load_data',\n",
    "    python_callable=load_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "upload = GCSToGCSOperator(\n",
    "    task_id='upload_to_gcs',\n",
    "    source_bucket='mybucket',\n",
    "    source_object='data/billing/{{ ds_nodash }}_billing.csv',\n",
    "    destination_bucket='mybucket',\n",
    "    destination_object='archive/cdrs/{{ ds_nodash }}_billing.csv',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "extract >> transform >> load >> upload\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
