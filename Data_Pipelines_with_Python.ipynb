{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Uwjnhit2BIJz"
   },
   "outputs": [],
   "source": [
    "# Data Pipelines\n",
    "# Extract Data, Transform, Load and Analyze.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"apache-airflow[celery]==2.5.3\" --constraint \"https://raw.githubusercontent.com/apache/airflow/constraints-2.5.3/constraints-3.7.txt\"\n",
    "!pip install \"apache-airflow-providers-google==6.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JUnqwKxKFCF9"
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.providers.google.cloud.operators.gcs import GCSToGCSOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'Safaricom',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 4, 10),\n",
    "    'email': ['newton.kipngeno@student.moringaschool.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 3,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'billing_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Pipeline for billing',\n",
    "    schedule_interval=timedelta(days=1),\n",
    ")\n",
    "\n",
    "# Functions\n",
    "# Extract data\n",
    "def extract_csv(filename):\n",
    "  data = pd.read_csv(filename)\n",
    "  return data\n",
    "\n",
    "# transform\n",
    "def transform_data(dataframe):\n",
    "  # Remove duplicates\n",
    "  dataframe = dataframe.drop_duplicates()\n",
    "  # remove nulls\n",
    "  dataframe = dataframe.dropna()\n",
    "  return dataframe\n",
    "\n",
    "#load data\n",
    "def load_data(df):\n",
    "    filename = datetime.today().strftime(\"%Y%m%d\") + '_billing.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    return filename\n",
    "\n",
    "def upload_to_gcs(filename):\n",
    "    gcs_hook = GoogleCloudStorageHook()\n",
    "    gcs_hook.upload(\n",
    "        bucket='mybucket',\n",
    "        object='data/cdrs/' + filename,\n",
    "        filename=filename,\n",
    "    )\n",
    "    \n",
    "extract = PythonOperator(\n",
    "    task_id='extract_csv',\n",
    "    python_callable=extract_csv,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "transform = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "load = PythonOperator(\n",
    "    task_id='load_data',\n",
    "    python_callable=load_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "upload = GCSToGCSOperator(\n",
    "    task_id='upload_to_gcs',\n",
    "    source_bucket='newton_bucket',\n",
    "    source_object='data/billing/{{ ds_nodash }}_billing.csv',\n",
    "    destination_bucket='newton_bucket',\n",
    "    destination_object='archive/cdrs/{{ ds_nodash }}_billing.csv',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "extract >> transform >> load >> upload\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
